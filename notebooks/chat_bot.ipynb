{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "05c4351b",
      "metadata": {
        "id": "05c4351b"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "f8964cac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8964cac",
        "outputId": "01df702b-c4cb-4ce5-eceb-f43d7dcd7f9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents': [{'tag': 'saludo',\n",
              "   'patterns': ['Hola',\n",
              "    '¿Cómo estás?',\n",
              "    'Buenos días',\n",
              "    '¡Hola!',\n",
              "    '¡Qué tal!',\n",
              "    'Quien eres'],\n",
              "   'responses': ['¡Hola! Soy tu asistente educativo. ¿En qué puedo ayudarte hoy?',\n",
              "    'Hola soy tu asistente para Identificar Patrones de Rendimiento y Bienestar psicológico de los estudiantes.']},\n",
              "  {'tag': 'identificar_parametros',\n",
              "   'patterns': ['¿Qué factores afectan mi rendimiento?',\n",
              "    '¿Cuáles son los parámetros clave para el bienestar?',\n",
              "    '¿Qué influye en mis calificaciones?',\n",
              "    '¿Cómo afecta la asistencia a mi desempeño?',\n",
              "    '¿Qué hábitos mejoran mi salud mental?'],\n",
              "   'responses': ['Los factores clave incluyen horas de estudio, asistencia, uso de recursos educativos y hábitos de sueño. ¿Te gustaría analizar tu situación actual?',\n",
              "    'Para el bienestar, es importante considerar las horas de sueño e interacción social. ¿Quieres saber más?']},\n",
              "  {'tag': 'analizar_relaciones',\n",
              "   'patterns': ['¿Cómo se relacionan las horas de estudio con las calificaciones?',\n",
              "    '¿Qué impacto tiene el sueño en mi rendimiento?',\n",
              "    '¿Cómo afecta la depresión a mi desempeño académico?',\n",
              "    '¿Qué correlación hay entre asistencia y notas?'],\n",
              "   'responses': ['Las horas de estudio tienen una correlación directa con las calificaciones. ¿Quieres que analice tus datos para darte una predicción?',\n",
              "    'El sueño es fundamental para el rendimiento. Menos de 6 horas puede afectar negativamente tus notas. ¿Te gustaría un análisis personalizado?']},\n",
              "  {'tag': 'predicciones',\n",
              "   'patterns': ['¿Cuál será mi calificación final?',\n",
              "    '¿Puedes predecir mi promedio?',\n",
              "    '¿Qué nota obtendré en matemáticas?',\n",
              "    '¿Cómo será mi desempeño este semestre?',\n",
              "    '¿Estoy en riesgo de depresión?'],\n",
              "   'responses': ['Puedo predecir tu calificación con base en tu historial. ¿Me proporcionas tus datos recientes?',\n",
              "    'Claro, para predecir tu promedio necesito información como tus notas parciales y asistencia. ¿Listo para comenzar?',\n",
              "    'Para evaluar el riesgo de depresión, necesito tu PHQ-9 y hábitos de sueño. ¿Puedes proporcionarme esos datos?']},\n",
              "  {'tag': 'recomendaciones',\n",
              "   'patterns': ['¿Cómo puedo mejorar mi rendimiento?',\n",
              "    '¿Qué hábitos de estudio son más efectivos?',\n",
              "    '¿Cómo mejorar mi bienestar emocional?',\n",
              "    'Me siento estresado, ¿qué puedo hacer?',\n",
              "    '¿Qué recursos educativos me recomiendas?'],\n",
              "   'responses': ['Para mejorar tu rendimiento, te recomiendo aumentar tus horas de estudio y mantener una asistencia regular. ¿Quieres un plan personalizado?',\n",
              "    'Para tu bienestar emocional, es importante dormir al menos 7 horas y mantener interacción social. ¿Te gustaría más recomendaciones?',\n",
              "    'Te recomiendo usar recursos como bibliotecas virtuales y tutorías. ¿Necesitas ayuda para acceder a ellos?']},\n",
              "  {'tag': 'integracion_api',\n",
              "   'patterns': ['¿Cómo puedo integrar esto con mi sistema educativo?',\n",
              "    '¿Ofrecen una API para predicciones?',\n",
              "    '¿Puedo conectar esto a mi plataforma de gestión?',\n",
              "    '¿Cómo accedo a la API?'],\n",
              "   'responses': ['Sí, ofrecemos una API para integrar predicciones y recomendaciones en sistemas educativos existentes. ¿Te gustaría conocer más detalles?',\n",
              "    'Nuestra API es escalable y personalizable. ¿Quieres que te envíe la documentación?']},\n",
              "  {'tag': 'norespuesta',\n",
              "   'patterns': [''],\n",
              "   'responses': ['No entendí tu consulta. ¿Puedes reformularla?',\n",
              "    'No detecté una respuesta válida. ¿En qué más puedo ayudarte?']},\n",
              "  {'tag': 'despedida',\n",
              "   'patterns': ['Adiós', 'Hasta luego', 'Nos vemos', 'Hasta pronto'],\n",
              "   'responses': ['¡Hasta luego! Recuerda que estoy aquí para ayudarte cuando lo necesites.',\n",
              "    '¡Adiós! No dudes en volver si tienes más preguntas.']},\n",
              "  {'tag': 'agradecimientos',\n",
              "   'patterns': ['gracias',\n",
              "    'muchas gracias',\n",
              "    'mil gracias',\n",
              "    'muy amable',\n",
              "    'se lo agradezco',\n",
              "    'fue de ayuda',\n",
              "    'gracias por la ayuda',\n",
              "    'muy agradecido',\n",
              "    'gracias por su tiempo'],\n",
              "   'responses': ['De nada, ¡estoy aquí para ayudarte!',\n",
              "    'Gracias a ti por confiar en mí. ¡Feliz de ser útil!',\n",
              "    'Fue un placer ayudarte. ¡No dudes en preguntar si necesitas más ayuda!']}]}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def guardar_json(datos, filename):\n",
        "    '''creacion de funcion para guardar\n",
        "    diccionario de conocimiento en formato json'''\n",
        "    archivo=open(filename,\"w\")\n",
        "    json.dump(datos,archivo,indent=4)\n",
        "\n",
        "datos = {\n",
        "    \"intents\": [\n",
        "        {\n",
        "            \"tag\": \"saludo\",\n",
        "            \"patterns\": [\n",
        "                \"Hola\",\n",
        "                \"¿Cómo estás?\",\n",
        "                \"Buenos días\",\n",
        "                \"¡Hola!\",\n",
        "                \"¡Qué tal!\",\n",
        "                \"Quien eres\"\n",
        "            ],\n",
        "            \"responses\": [\n",
        "                \"¡Hola! Soy tu asistente educativo. ¿En qué puedo ayudarte hoy?\",\n",
        "                \"Hola soy tu asistente para Identificar Patrones de Rendimiento y Bienestar psicológico de los estudiantes.\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"tag\": \"identificar_parametros\",\n",
        "            \"patterns\": [\n",
        "                \"¿Qué factores afectan mi rendimiento?\",\n",
        "                \"¿Cuáles son los parámetros clave para el bienestar?\",\n",
        "                \"¿Qué influye en mis calificaciones?\",\n",
        "                \"¿Cómo afecta la asistencia a mi desempeño?\",\n",
        "                \"¿Qué hábitos mejoran mi salud mental?\"\n",
        "            ],\n",
        "            \"responses\": [\n",
        "                \"Los factores clave incluyen horas de estudio, asistencia, uso de recursos educativos y hábitos de sueño. ¿Te gustaría analizar tu situación actual?\",\n",
        "                \"Para el bienestar, es importante considerar las horas de sueño e interacción social. ¿Quieres saber más?\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"tag\": \"analizar_relaciones\",\n",
        "            \"patterns\": [\n",
        "                \"¿Cómo se relacionan las horas de estudio con las calificaciones?\",\n",
        "                \"¿Qué impacto tiene el sueño en mi rendimiento?\",\n",
        "                \"¿Cómo afecta la depresión a mi desempeño académico?\",\n",
        "                \"¿Qué correlación hay entre asistencia y notas?\"\n",
        "            ],\n",
        "            \"responses\": [\n",
        "                \"Las horas de estudio tienen una correlación directa con las calificaciones. ¿Quieres que analice tus datos para darte una predicción?\",\n",
        "                \"El sueño es fundamental para el rendimiento. Menos de 6 horas puede afectar negativamente tus notas. ¿Te gustaría un análisis personalizado?\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"tag\": \"predicciones\",\n",
        "            \"patterns\": [\n",
        "                \"¿Cuál será mi calificación final?\",\n",
        "                \"¿Puedes predecir mi promedio?\",\n",
        "                \"¿Qué nota obtendré en matemáticas?\",\n",
        "                \"¿Cómo será mi desempeño este semestre?\",\n",
        "                \"¿Estoy en riesgo de depresión?\"\n",
        "            ],\n",
        "            \"responses\": [\n",
        "                \"Puedo predecir tu calificación con base en tu historial. ¿Me proporcionas tus datos recientes?\",\n",
        "                \"Claro, para predecir tu promedio necesito información como tus notas parciales y asistencia. ¿Listo para comenzar?\",\n",
        "                \"Para evaluar el riesgo de depresión, necesito tu PHQ-9 y hábitos de sueño. ¿Puedes proporcionarme esos datos?\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"tag\": \"recomendaciones\",\n",
        "            \"patterns\": [\n",
        "                \"¿Cómo puedo mejorar mi rendimiento?\",\n",
        "                \"¿Qué hábitos de estudio son más efectivos?\",\n",
        "                \"¿Cómo mejorar mi bienestar emocional?\",\n",
        "                \"Me siento estresado, ¿qué puedo hacer?\",\n",
        "                \"¿Qué recursos educativos me recomiendas?\"\n",
        "            ],\n",
        "            \"responses\": [\n",
        "                \"Para mejorar tu rendimiento, te recomiendo aumentar tus horas de estudio y mantener una asistencia regular. ¿Quieres un plan personalizado?\",\n",
        "                \"Para tu bienestar emocional, es importante dormir al menos 7 horas y mantener interacción social. ¿Te gustaría más recomendaciones?\",\n",
        "                \"Te recomiendo usar recursos como bibliotecas virtuales y tutorías. ¿Necesitas ayuda para acceder a ellos?\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"tag\": \"integracion_api\",\n",
        "            \"patterns\": [\n",
        "                \"¿Cómo puedo integrar esto con mi sistema educativo?\",\n",
        "                \"¿Ofrecen una API para predicciones?\",\n",
        "                \"¿Puedo conectar esto a mi plataforma de gestión?\",\n",
        "                \"¿Cómo accedo a la API?\"\n",
        "            ],\n",
        "            \"responses\": [\n",
        "                \"Sí, ofrecemos una API para integrar predicciones y recomendaciones en sistemas educativos existentes. ¿Te gustaría conocer más detalles?\",\n",
        "                \"Nuestra API es escalable y personalizable. ¿Quieres que te envíe la documentación?\"\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"tag\": \"norespuesta\",\n",
        "            \"patterns\": [\n",
        "                \"\"\n",
        "            ],\n",
        "            \"responses\": [\n",
        "                \"No entendí tu consulta. ¿Puedes reformularla?\",\n",
        "                \"No detecté una respuesta válida. ¿En qué más puedo ayudarte?\"\n",
        "            ]\n",
        "        },\n",
        "         {\n",
        "            \"tag\": \"despedida\",\n",
        "            \"patterns\": [\n",
        "                \"Adiós\",\n",
        "                \"Hasta luego\",\n",
        "                \"Nos vemos\",\n",
        "                \"Hasta pronto\"\n",
        "            ],\n",
        "            \"responses\": [\n",
        "                \"¡Hasta luego! Recuerda que estoy aquí para ayudarte cuando lo necesites.\",\n",
        "                \"¡Adiós! No dudes en volver si tienes más preguntas.\"\n",
        "            ]\n",
        "        },\n",
        "         {\n",
        "            \"tag\": \"agradecimientos\",\n",
        "            \"patterns\": [\n",
        "                \"gracias\",\n",
        "                \"muchas gracias\",\n",
        "                \"mil gracias\",\n",
        "                \"muy amable\",\n",
        "                \"se lo agradezco\",\n",
        "                \"fue de ayuda\",\n",
        "                \"gracias por la ayuda\",\n",
        "                \"muy agradecido\",\n",
        "                \"gracias por su tiempo\"\n",
        "            ],\n",
        "            \"responses\": [\n",
        "                \"De nada, ¡estoy aquí para ayudarte!\",\n",
        "                \"Gracias a ti por confiar en mí. ¡Feliz de ser útil!\",\n",
        "                \"Fue un placer ayudarte. ¡No dudes en preguntar si necesitas más ayuda!\"\n",
        "            ]\n",
        "        },\n",
        "\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Guardado de diccionario de conocimiento en formato json.\n",
        "guardar_json(datos, 'intents.json')\n",
        "datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "80fb2575",
      "metadata": {
        "id": "80fb2575"
      },
      "outputs": [],
      "source": [
        "# Cargar el archivo JSON\n",
        "with open('intents.json') as file:\n",
        "    intents = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "68152bc5",
      "metadata": {
        "id": "68152bc5"
      },
      "outputs": [],
      "source": [
        "# Inicializar el stemmer y el encoder\n",
        "stemmer = PorterStemmer()\n",
        "encoder = LabelEncoder() # Similar al Integer Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "dadd0875",
      "metadata": {
        "id": "dadd0875"
      },
      "outputs": [],
      "source": [
        "# Preparar los datos\n",
        "patterns = []\n",
        "responses = []\n",
        "tags = []\n",
        "\n",
        "# Llenar las listas con los datos del JSON\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        patterns.append(pattern)\n",
        "        responses.append(intent['responses'])\n",
        "        tags.append(intent['tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d0067bda",
      "metadata": {
        "id": "d0067bda"
      },
      "outputs": [],
      "source": [
        "# Tokenización y Stemming\n",
        "def tokenize_and_stem(sentence):\n",
        "    words = nltk.word_tokenize(sentence)\n",
        "    words = [stemmer.stem(w.lower()) for w in words if w.isalnum()]\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC8GHaHcVoVJ",
        "outputId": "6da85b4c-bc52-4a3b-dbcc-86f914613499"
      },
      "id": "CC8GHaHcVoVJ",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18HNw2oQWBPT",
        "outputId": "e284d4fd-d306-44cf-a039-04e08a2dc587"
      },
      "id": "18HNw2oQWBPT",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "48002940",
      "metadata": {
        "id": "48002940"
      },
      "outputs": [],
      "source": [
        "# Crear el Bag of Words\n",
        "all_words = []\n",
        "for pattern in patterns:\n",
        "    words = tokenize_and_stem(pattern)\n",
        "    all_words.extend(words)\n",
        "\n",
        "all_words = sorted(list(set(all_words)))\n",
        "\n",
        "# Crear el Bag of Words (BoW)\n",
        "vectorizer = CountVectorizer(vocabulary=all_words)\n",
        "X_train = vectorizer.transform(patterns).toarray()\n",
        "\n",
        "# Codificar las etiquetas\n",
        "y_train = encoder.fit_transform(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "673f772b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "673f772b",
        "outputId": "b2d3b48e-c6e3-4291-8fb8-b0d3a448fb73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1450 - loss: 2.1976\n",
            "Epoch 2/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3001 - loss: 2.1154 \n",
            "Epoch 3/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6026 - loss: 2.0093 \n",
            "Epoch 4/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7105 - loss: 1.9359  \n",
            "Epoch 5/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7863 - loss: 1.8609  \n",
            "Epoch 6/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8546 - loss: 1.7344 \n",
            "Epoch 7/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8128 - loss: 1.6341  \n",
            "Epoch 8/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8446 - loss: 1.5199 \n",
            "Epoch 9/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7680 - loss: 1.4661 \n",
            "Epoch 10/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8595 - loss: 1.2064 \n",
            "Epoch 11/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8685 - loss: 1.1853 \n",
            "Epoch 12/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8881 - loss: 0.9980  \n",
            "Epoch 13/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8101 - loss: 1.0335 \n",
            "Epoch 14/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8170 - loss: 0.9700 \n",
            "Epoch 15/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8998 - loss: 0.6946 \n",
            "Epoch 16/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9085 - loss: 0.5144 \n",
            "Epoch 17/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8490 - loss: 0.6089 \n",
            "Epoch 18/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8960 - loss: 0.4777  \n",
            "Epoch 19/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9068 - loss: 0.4327 \n",
            "Epoch 20/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8387 - loss: 0.6380 \n",
            "Epoch 21/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8603 - loss: 0.4254  \n",
            "Epoch 22/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9273 - loss: 0.3423 \n",
            "Epoch 23/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9120 - loss: 0.2964 \n",
            "Epoch 24/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8486 - loss: 0.4134 \n",
            "Epoch 25/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9068 - loss: 0.3356 \n",
            "Epoch 26/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8106 - loss: 0.4591 \n",
            "Epoch 27/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8983 - loss: 0.2756 \n",
            "Epoch 28/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9362 - loss: 0.2192 \n",
            "Epoch 29/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9115 - loss: 0.2812 \n",
            "Epoch 30/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9392 - loss: 0.2265 \n",
            "Epoch 31/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9292 - loss: 0.2078 \n",
            "Epoch 32/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9068 - loss: 0.2761 \n",
            "Epoch 33/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8178 - loss: 0.3863 \n",
            "Epoch 34/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8690 - loss: 0.3012 \n",
            "Epoch 35/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8748 - loss: 0.2336  \n",
            "Epoch 36/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9078 - loss: 0.2662 \n",
            "Epoch 37/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7866 - loss: 0.3400  \n",
            "Epoch 38/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8875 - loss: 0.3129 \n",
            "Epoch 39/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8209 - loss: 0.2695 \n",
            "Epoch 40/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8620 - loss: 0.2599 \n",
            "Epoch 41/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9198 - loss: 0.2171 \n",
            "Epoch 42/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8310 - loss: 0.3546 \n",
            "Epoch 43/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9312 - loss: 0.2077 \n",
            "Epoch 44/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9230 - loss: 0.2111 \n",
            "Epoch 45/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8585 - loss: 0.2483  \n",
            "Epoch 46/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8225 - loss: 0.3114 \n",
            "Epoch 47/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8495 - loss: 0.2571 \n",
            "Epoch 48/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8830 - loss: 0.2696 \n",
            "Epoch 49/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8841 - loss: 0.2629 \n",
            "Epoch 50/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7735 - loss: 0.3744 \n",
            "Epoch 51/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8733 - loss: 0.1916 \n",
            "Epoch 52/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8635 - loss: 0.2127 \n",
            "Epoch 53/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9015 - loss: 0.2136 \n",
            "Epoch 54/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9305 - loss: 0.1582 \n",
            "Epoch 55/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9258 - loss: 0.2040 \n",
            "Epoch 56/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9504 - loss: 0.1640 \n",
            "Epoch 57/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8781 - loss: 0.2812 \n",
            "Epoch 58/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8968 - loss: 0.2582 \n",
            "Epoch 59/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9402 - loss: 0.1517 \n",
            "Epoch 60/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8878 - loss: 0.1826 \n",
            "Epoch 61/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9458 - loss: 0.1463 \n",
            "Epoch 62/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.1997 \n",
            "Epoch 63/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.3768 \n",
            "Epoch 64/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8051 - loss: 0.3413 \n",
            "Epoch 65/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9333 - loss: 0.1529 \n",
            "Epoch 66/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8650 - loss: 0.2245 \n",
            "Epoch 67/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8830 - loss: 0.2018 \n",
            "Epoch 68/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8946 - loss: 0.2168 \n",
            "Epoch 69/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7826 - loss: 0.3044 \n",
            "Epoch 70/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8493 - loss: 0.2895 \n",
            "Epoch 71/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8305 - loss: 0.2817  \n",
            "Epoch 72/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8446 - loss: 0.3208 \n",
            "Epoch 73/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9056 - loss: 0.1511 \n",
            "Epoch 74/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8518 - loss: 0.2311 \n",
            "Epoch 75/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9297 - loss: 0.1304 \n",
            "Epoch 76/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8545 - loss: 0.2344 \n",
            "Epoch 77/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7776 - loss: 0.3402 \n",
            "Epoch 78/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8980 - loss: 0.2024 \n",
            "Epoch 79/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8678 - loss: 0.2562 \n",
            "Epoch 80/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9053 - loss: 0.1873 \n",
            "Epoch 81/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8715 - loss: 0.2652 \n",
            "Epoch 82/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9515 - loss: 0.1188 \n",
            "Epoch 83/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8545 - loss: 0.2264  \n",
            "Epoch 84/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8313 - loss: 0.2863 \n",
            "Epoch 85/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8335 - loss: 0.2834 \n",
            "Epoch 86/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7778 - loss: 0.3304 \n",
            "Epoch 87/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8545 - loss: 0.1961 \n",
            "Epoch 88/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8545 - loss: 0.2079 \n",
            "Epoch 89/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8273 - loss: 0.2701  \n",
            "Epoch 90/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9405 - loss: 0.1131  \n",
            "Epoch 91/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8705 - loss: 0.2133     \n",
            "Epoch 92/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8437 - loss: 0.3021 \n",
            "Epoch 93/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9338 - loss: 0.1501 \n",
            "Epoch 94/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9095 - loss: 0.1681 \n",
            "Epoch 95/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8558 - loss: 0.3146 \n",
            "Epoch 96/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9053 - loss: 0.2344 \n",
            "Epoch 97/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8666 - loss: 0.2555 \n",
            "Epoch 98/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8915 - loss: 0.1646 \n",
            "Epoch 99/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8533 - loss: 0.3462 \n",
            "Epoch 100/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8400 - loss: 0.3166\n",
            "Epoch 101/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8753 - loss: 0.2602 \n",
            "Epoch 102/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9110 - loss: 0.2154 \n",
            "Epoch 103/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8797 - loss: 0.1610 \n",
            "Epoch 104/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8422 - loss: 0.2547 \n",
            "Epoch 105/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8673 - loss: 0.2499 \n",
            "Epoch 106/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8730 - loss: 0.2601 \n",
            "Epoch 107/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8968 - loss: 0.1797 \n",
            "Epoch 108/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8323 - loss: 0.3217 \n",
            "Epoch 109/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8549 - loss: 0.2027     \n",
            "Epoch 110/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8643 - loss: 0.1951 \n",
            "Epoch 111/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9358 - loss: 0.1772 \n",
            "Epoch 112/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8891 - loss: 0.2333 \n",
            "Epoch 113/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8401 - loss: 0.2521 \n",
            "Epoch 114/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8910 - loss: 0.2140 \n",
            "Epoch 115/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8835 - loss: 0.2030 \n",
            "Epoch 116/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8425 - loss: 0.2614  \n",
            "Epoch 117/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8530 - loss: 0.2113 \n",
            "Epoch 118/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8450 - loss: 0.2727 \n",
            "Epoch 119/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8273 - loss: 0.2539 \n",
            "Epoch 120/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8623 - loss: 0.2655     \n",
            "Epoch 121/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8525 - loss: 0.2581 \n",
            "Epoch 122/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9392 - loss: 0.1513 \n",
            "Epoch 123/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7868 - loss: 0.3341  \n",
            "Epoch 124/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9093 - loss: 0.1780 \n",
            "Epoch 125/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8735 - loss: 0.2410  \n",
            "Epoch 126/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9196 - loss: 0.1591 \n",
            "Epoch 127/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8216 - loss: 0.2479 \n",
            "Epoch 128/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9018 - loss: 0.1754     \n",
            "Epoch 129/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9272 - loss: 0.1311     \n",
            "Epoch 130/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8846 - loss: 0.2610 \n",
            "Epoch 131/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8168 - loss: 0.2829 \n",
            "Epoch 132/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8333 - loss: 0.3075 \n",
            "Epoch 133/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8925 - loss: 0.2188 \n",
            "Epoch 134/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9318 - loss: 0.2066  \n",
            "Epoch 135/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9131 - loss: 0.1727 \n",
            "Epoch 136/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9230 - loss: 0.1488     \n",
            "Epoch 137/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8812 - loss: 0.2233 \n",
            "Epoch 138/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8943 - loss: 0.2360 \n",
            "Epoch 139/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9120 - loss: 0.1754 \n",
            "Epoch 140/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8301 - loss: 0.2517 \n",
            "Epoch 141/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9377 - loss: 0.1890  \n",
            "Epoch 142/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9013 - loss: 0.2106 \n",
            "Epoch 143/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8906 - loss: 0.2189 \n",
            "Epoch 144/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8139 - loss: 0.2493 \n",
            "Epoch 145/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8603 - loss: 0.1863     \n",
            "Epoch 146/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8626 - loss: 0.2398  \n",
            "Epoch 147/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8490 - loss: 0.2255 \n",
            "Epoch 148/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8173 - loss: 0.3595 \n",
            "Epoch 149/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9602 - loss: 0.1172 \n",
            "Epoch 150/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8690 - loss: 0.2008     \n",
            "Epoch 151/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9110 - loss: 0.2275 \n",
            "Epoch 152/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8591 - loss: 0.2307 \n",
            "Epoch 153/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8880 - loss: 0.2235 \n",
            "Epoch 154/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8326 - loss: 0.2799 \n",
            "Epoch 155/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8256 - loss: 0.3316 \n",
            "Epoch 156/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8116 - loss: 0.3544 \n",
            "Epoch 157/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8623 - loss: 0.2624  \n",
            "Epoch 158/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8633 - loss: 0.2032     \n",
            "Epoch 159/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9123 - loss: 0.2261 \n",
            "Epoch 160/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8680 - loss: 0.2271 \n",
            "Epoch 161/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8833 - loss: 0.1962 \n",
            "Epoch 162/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9420 - loss: 0.1382 \n",
            "Epoch 163/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8483 - loss: 0.2491     \n",
            "Epoch 164/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8391 - loss: 0.2456 \n",
            "Epoch 165/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8235 - loss: 0.2671 \n",
            "Epoch 166/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9475 - loss: 0.1120     \n",
            "Epoch 167/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8891 - loss: 0.2527  \n",
            "Epoch 168/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8351 - loss: 0.2535 \n",
            "Epoch 169/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8323 - loss: 0.3866 \n",
            "Epoch 170/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8478 - loss: 0.2459 \n",
            "Epoch 171/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8816 - loss: 0.3186 \n",
            "Epoch 172/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8716 - loss: 0.2110     \n",
            "Epoch 173/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8576 - loss: 0.2365 \n",
            "Epoch 174/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9373 - loss: 0.1912 \n",
            "Epoch 175/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8915 - loss: 0.1936     \n",
            "Epoch 176/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7945 - loss: 0.2850 \n",
            "Epoch 177/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8778 - loss: 0.2145 \n",
            "Epoch 178/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9003 - loss: 0.1842 \n",
            "Epoch 179/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9271 - loss: 0.1287 \n",
            "Epoch 180/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7453 - loss: 0.3491 \n",
            "Epoch 181/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8740 - loss: 0.2230     \n",
            "Epoch 182/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8830 - loss: 0.2615 \n",
            "Epoch 183/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9131 - loss: 0.1847     \n",
            "Epoch 184/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9367 - loss: 0.2314 \n",
            "Epoch 185/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8378 - loss: 0.2744 \n",
            "Epoch 186/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9231 - loss: 0.1941 \n",
            "Epoch 187/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9112 - loss: 0.2047 \n",
            "Epoch 188/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7866 - loss: 0.3882 \n",
            "Epoch 189/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8576 - loss: 0.3155 \n",
            "Epoch 190/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8650 - loss: 0.2243 \n",
            "Epoch 191/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8425 - loss: 0.2942 \n",
            "Epoch 192/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8083 - loss: 0.3350 \n",
            "Epoch 193/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9024 - loss: 0.1778     \n",
            "Epoch 194/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.2813 \n",
            "Epoch 195/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9048 - loss: 0.1763 \n",
            "Epoch 196/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9223 - loss: 0.2073 \n",
            "Epoch 197/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8966 - loss: 0.1682 \n",
            "Epoch 198/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9185 - loss: 0.2091     \n",
            "Epoch 199/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8573 - loss: 0.3089 \n",
            "Epoch 200/200\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9038 - loss: 0.1883 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b485fec7e50>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# Crear la red neuronal\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(len(set(tags)), activation='softmax'))\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "f1ae63c0",
      "metadata": {
        "id": "f1ae63c0"
      },
      "outputs": [],
      "source": [
        "# Función para obtener la respuesta más probable\n",
        "def chatbot_response(text):\n",
        "    # Preprocesar el texto de entrada\n",
        "    text_words = tokenize_and_stem(text)\n",
        "    bow = np.zeros(len(all_words))\n",
        "\n",
        "    for word in text_words:\n",
        "        if word in all_words:\n",
        "            bow[all_words.index(word)] = 1\n",
        "\n",
        "    # Predecir la categoría\n",
        "    prediction = model.predict(np.array([bow]))[0]\n",
        "    tag = encoder.inverse_transform([np.argmax(prediction)])\n",
        "\n",
        "    # Buscar una respuesta dentro de la categoría\n",
        "    for intent in intents['intents']:\n",
        "        if intent['tag'] == tag:\n",
        "            return random.choice(intent['responses'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "bf5d68c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf5d68c8",
        "outputId": "f7acecc9-4b34-4bae-acfd-4e37780abe07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¡Hola! Soy tu chatbot Identificador de Patrones de Rendimiento y Bienestar Estudiantil . Escribe 'exit' para terminar.\n",
            "Tú: hola\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
            "Chatbot: ¡Hola! Soy tu asistente educativo. ¿En qué puedo ayudarte hoy?\n",
            "Tú: como puedo mejorar\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Chatbot: Para mejorar tu rendimiento, te recomiendo aumentar tus horas de estudio y mantener una asistencia regular. ¿Quieres un plan personalizado?\n",
            "Tú: como uso la ap\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Chatbot: De nada, ¡estoy aquí para ayudarte!\n",
            "Tú: como uso la api\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Chatbot: Nuestra API es escalable y personalizable. ¿Quieres que te envíe la documentación?\n",
            "Tú: gracias\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Chatbot: Fue un placer ayudarte. ¡No dudes en preguntar si necesitas más ayuda!\n",
            "Tú: que tal estas\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Chatbot: ¡Hola! Soy tu asistente educativo. ¿En qué puedo ayudarte hoy?\n",
            "Tú: exit\n"
          ]
        }
      ],
      "source": [
        "# Probar el chatbot\n",
        "print(\"¡Hola! Soy tu chatbot Identificador de Patrones de Rendimiento y Bienestar Estudiantil . Escribe 'exit' para terminar.\")\n",
        "while True:\n",
        "    user_input = input(\"Tú: \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        break\n",
        "    response = chatbot_response(user_input)\n",
        "    print(f\"Chatbot: {response}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sicve",
      "language": "python",
      "name": "sicve"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}